///////////////////////////////////////////////////////////////////////////////
    Copyright (c) 2000, 2021, Oracle and/or its affiliates.

    Licensed under the Universal Permissive License v 1.0 as shown at
    http://oss.oracle.com/licenses/upl.
///////////////////////////////////////////////////////////////////////////////
= Non Blocking Data Sources
:description: Integration with data sources with a non-blocking API
:keywords: coherence, partition, documentation

// DO NOT remove this header - it might look like a duplicate of the header above, but
// both they serve a purpose, and the docs will look wrong if it is removed.
== Non Blocking Data Sources

Coherence provides a means of {commercial-docs-base-url}/develop-applications/caching-data-sources.html#GUID-9FAD1BFB-5063-4995-B0A7-3C6F9C64F600[integrating with underlying data sources] using a number of existing strategies; namely, read-through, write-through, write-behind and refresh-ahead.

Coherence now also provides a {javadoc-root}/com/tangosol/net/cache/NonBlockingEntryStore.html[NonBlockingEntryStore] interface for integrating with data sources that provide non-blocking APIs.
This new strategy is similar in nature to write-behind, as it is asynchronous to the original mutation, however does not require a queue to defer the call to the store and immediately passes the intent to store to the implementer.
The implementer can in-turn immediately call the non-blocking api of the data source and on success or failure a future can pass that information to the provided `StoreObserver` via `onNext` or `onError` respectively.
The primary methods of the `NonBlockingEntryStore` are highlighted below:

[source,java]
----
public interface NonBlockingEntryStore<K, V>
    {
    public void load(BinaryEntry<K, V> binEntry, StoreObserver<K, V> observer);

    public void store(BinaryEntry<K, V> binEntry, StoreObserver<K, V> observer);

    public void erase(BinaryEntry<K, V> binEntry);
    }
----

There are similar methods to the above in existing {javadoc-root}/com/tangosol/net/cache/CacheStore.html[CacheStore] and {javadoc-root}/com/tangosol/net/cache/BinaryEntryStore.html[BinaryEntryStore] interfaces, however with the {javadoc-root}/com/tangosol/net/cache/NonBlockingEntryStore.html[NonBlockingEntryStore] interface the calls are non-blocking thus Coherence does not expect the operation to be completed when control is returned. To allow the implementer to notify Coherence of operation completion, the {javadoc-root}/com/tangosol/net/cache/StoreObserver.html[StoreObserver] is provided and *must* be called upon success or failure. This allows Coherence to process the result of the operation.

It is worth pointing out that similar to the write-behind strategy upon failure, and therefore restore of primary partitions, Coherence will call `NonBlockingEntryStore.store` for the entries it did not receive a success or error notification for. This provides at least once semantics allowing implementers to call the non-blocking data source if deemed necessary.

The diagrams below illustrate the flow from the initial request, to the invocation of the NonBlockingEntryStore on the storage enabled nodes:

* for a `get()` operation inducing a load:

image:/docs/images/08_non_blocking_load.png[link="/docs/images/08_non_blocking_load.png",width=80%]

<1> the application calls `get()` on entry `A` that is not in the cache yet.
<2> a request goes to the storage member that owns the entry, in this instance JVM2. Entry ownership, and thus partition ownership, is determined algorithmically based on the raw (or binary) value of the key and the number of partitions the associated partitioned service is configured with.
Since it has not been accessed yet or has expired, a miss takes place and the call is relayed to the configure entry store.
<3> the `load()` operation for the entry store that implements `NonBlockingEntryStore` is called; custom logic is provided a {javadoc-root}/com/tangosol/util/BinaryEntry.html[BinaryEntry] with a null initial value
and a {javadoc-root}/com/tangosol/net/cache/StoreObserver.html[StoreObserver]. The implementer performs the datastore operation(s) necessary to populate the cache entry.
<4>  When the operation on the underlying data source completes, the implementation will call either `observer.onNext` or `observer.onError`, whether the value was successfully loaded or not.
The implementer will update the `BinaryEntry` via `setValue` or `updateBinaryValue`, prior to calling `onNext`. This will allow Coherence to ensure data is inserted in the primary partition owner (JVM2) and backed up accordingly.
<5> the primary partition owner sends the value to another storage member in the cluster for backup purposes.
<6> the entry value is sent back to the calling application where a transient reference is kept.
Note that although the data source operation can be performed asynchronously and the call to `load()` does not need to wait for its completion to return, the `get()` invocation is synchronous from the caller's perspective.

----
----
* for a `put()` operation:

image:/docs/images/08_non_blocking_store.png[link="/docs/images/08_non_blocking_store.png",width=80%]

<1> the application calls `put()` on entry `A` with value `A`.
<2> the entry is stored on the owning member.
<3> since the cache is configured with a `NonBlockingEntryStore`, the `store()` operation is called. `store()` is provided a `BinaryEntry` and a a {javadoc-root}/com/tangosol/net/cache/StoreObserver.html[StoreObserver].
The implementer performs the datastore operation(s) necessary to save the cache entry into a datastore.
<4> at this point, the `store()` call of the `NonBlockingEntryStore` can return, and `put()` will then give control back to the calling application.
<5> the datastore asynchronously performs the datastore operation(s) necessary to save the cache entry into a datastore, then calls the `observer.onNext()` method for normal operations (or `observer.onError()` in case of a problem).
If necessary (for example, the value of the `BinaryEntry` has been updated), the value is put back into the cache.
<6> the value is then sent to the backup owning member for safekeeping.

----
----

* `getAll()` functions comparably to `get()`, except it processes a set of entries.
This provides an opportunity for an implementer to optimize batch operations (multi-entry) against the datasource thus reduce the communication overhead with the datasource.
Once the associated entry has been successfully written the implementer must call `StoreObserver.onNext` passing the relevant entry (or `onError()` if an error occurred processing this particular entry).

[NOTE]
====
Coherence expects all entries to be processed before concluding.
====

* `putAll()` also functions comparably to `put()`, except on a set of entries. The same expectation is in effect here: either all entries are processed using `onNext()/onError()`, or `onComplete()` can be used to interrupt the operation. The difference with `putAll()` is that the caller will not wait for completion, thus any exception will not be thrown but printed out in the log.

* the `remove()` operation functions in the same way as CacheStore or BinaryEntryStore from the application standpoint.

Besides providing a natural way of integrating with non-blocking data stores, this model takes advantage of the benefits of such stores in terms of performance and scalability.

=== NonBlockingEntryStore

Certain data source libraries have APIs that do not necessitate the caller to wait for the result to come back before doing something else. For example, making HTTP calls can lead to relatively long waits between the time a request to store data is sent and the response comes back. By implementing non-blocking APIs, the caller can immediately do other work without having to wait for the actual store operation to complete.

By implementing the `NonBlockingEntryStore` interface, the store implementer will be able to use non-blocking APIs in a more natural way.

`NonBlockingEntryStore` is being provided in the context of {commercial-docs-base-url}/develop-applications/caching-data-sources.html#GUID-6F84A2D6-43FE-4852-B48F-2A250CABEB36[pluggable data stores]: in order to use it, an implementation class needs to be provided and configured. This class will either load, store or remove data from the data source by way of a `ReadWriteBackingMap`. This backing map provides two elements: an internal map to cache the data, and a data source access portion to interact with the data base.

The `NonBlockingEntryStore` interface is provided the `BinaryEntry` that represents the `load`, `store` or `erase` operation. This provides an opportunity for implementers to avoid deserialization if desired; this is similar to `BinaryEntryStore`. Avoiding deserialization generally is possible if the raw binary is stored in the downstream system, or the binary can be navigated to extract relevant parts, as opposed to deserializing the entire key or value. Note: `getKey`, `getValue` and `getOriginalValue` will induce deserialization for the first call.

=== How to Use

==== Configuration

To specify a non-blocking cache store implementation, provide the implementation class name within the read-write-backing-map-scheme as shown below.

[source,xml]
----
...
<cache-config xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
   xmlns="http://xmlns.oracle.com/coherence/coherence-cache-config"
   xsi:schemaLocation="http://xmlns.oracle.com/coherence/coherence-cache-config
   coherence-cache-config.xsd">
    <cache-mapping>
...
        <cache-name>myCache</cache-name>
        <scheme-name>distributed-rwbm-nonblocking</scheme-name>
...
    </cache-mapping>

    <distributed-scheme>
...
        <scheme-name>distributed-rwbm-nonblocking</scheme-name>
        <backing-map-scheme>
            <read-write-backing-map-scheme>

                <cachestore-scheme>
                    <class-scheme>
                        <class-name>com.company.NonBlockingStoreImpl</class-name>
                    </class-scheme>
                </cachestore-scheme>

            </read-write-backing-map-scheme>
        </backing-map-scheme>
        <autostart>true</autostart>
...
    </distributed-scheme>

</cache-config>
----

==== Implementation

Once configured, a class implementing the `NonBlockingEntryStore` interface needs to be added to the added to the classpath of the storage enabled members. See below for example code.

With the class in place, the equivalency below is established:

- `get()` -invokes-> `load()` Note: If data is already in the cache, `load()` does not get called. Also, calling `get()` will wait for `onNext()`/`onError()` to complete before returning.
- `getAll()` -invokes-> `loadAll()`
- `put()` -invokes-> `store()`
- `putAll()` -invokes-> `storeAll()`
- `remove()` -invokes-> `erase()`
- `removeAll()` -invokes-> `eraseAll()`

The code below contains portions of code is using a reactive API to access a data source.

[source,java]
----
...
/**
 * An example NonBlockingEntryStore implementation
 */
public class ExampleNonBlockingEntryStore<K, V>
    {
    @Override
    public void load(BinaryEntry<K, V> binEntry, StoreObserver<K, V> observer)
        {
        K key = binEntry.getKey();

        Flux.from(getConnection())
                .flatMap(connection -> connection.createStatement(LOAD_STMT)
                        .bind("$1", key)
                        .execute())
                .flatMap(result ->
                         result.map((row, meta) ->
                                 {
                                 return
                                     new Student(
                                         (String) row.get("name"),
                                         (String) row.get("address"));
                                 }
                         ))
                .collectList()
                .doOnNext(s ->
                          {
                          binEntry.setValue((V) s.get(0));
                          observer.onNext(binEntry);
                          })
                .doOnError(t ->
                           {
                           if (t instanceof IndexOutOfBoundsException)
                               {
                               CacheFactory.log("Could not find row for key: " + key);
                               }
                           else
                               {
                               CacheFactory.log("Error: " + t);
                               }
                           observer.onError(binEntry, new Exception(t));
                           })
                .subscribe();
        }
...
    @Override
    public void store(BinaryEntry<K, V> binEntry, StoreObserver<K, V> observer)
        {
        K       key      = binEntry.getKey();
        Student oStudent = (Student) binEntry.getValue();

        Flux.from(getConnection())
                .flatMap(connection -> connection.createStatement(STORE_STMT)
                        .bind("$1", key)
                        .bind("$2", oStudent.getName())
                        .bind("$3", oStudent.getAddress())
                        .execute())
                .flatMap(Result::getRowsUpdated)
                .doOnNext((s) ->
                          {
                          CacheFactory.log("store done, rows updated: " + s);
                          observer.onNext(binEntry);
                          })
                .doOnError(t -> new Exception(t))
                .subscribe();
        }
...
    private static final String STORE_STMT = "INSERT INTO student VALUES ($1, $2, $3) ON conflict (id) DO UPDATE SET name=$2, address=$2";
    private static final String LOAD_STMT = "SELECT NAME, ADDRESS FROM student WHERE id=$1";
----

Be sure to consult these {commercial-docs-base-url}/develop-applications/caching-data-sources.html#GUID-106C9FE6-6407-4375-A297-AC99D779B77E[best practices] when implementing an entry store for your data sources.